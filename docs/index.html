<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LiteAttention: A Temporal Sparse Attention for Diffusion Transformers</title>
    <meta name="description" content="LiteAttention achieves up to 54% attention sparsity on production video diffusion models with no degradation in generation quality.">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', sans-serif;
            line-height: 1.6;
            color: #333;
            background: #ffffff;
        }

        .container {
            max-width: 1100px;
            margin: 0 auto;
            padding: 40px 20px;
        }

        header {
            text-align: center;
            padding: 60px 20px 40px;
            margin-bottom: 60px;
        }

        h1 {
            font-size: 2.8em;
            margin-bottom: 30px;
            color: #000;
            font-weight: 700;
            line-height: 1.2;
        }

        .authors {
            margin: 25px 0;
            font-size: 1.15em;
            color: #333;
            line-height: 1.8;
        }

        .authors a {
            color: #0066cc;
            text-decoration: none;
        }

        .authors a:hover {
            text-decoration: underline;
        }

        .affiliation {
            margin-top: 15px;
            font-size: 1.05em;
            color: #666;
        }

        .affiliation a {
            color: #0066cc;
            text-decoration: none;
        }

        .affiliation a:hover {
            text-decoration: underline;
        }

        .links {
            display: flex;
            gap: 15px;
            justify-content: center;
            flex-wrap: wrap;
            margin-top: 35px;
        }

        .btn {
            display: inline-block;
            padding: 10px 28px;
            background: #0066cc;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            font-weight: 500;
            transition: background 0.2s;
            font-size: 0.95em;
        }

        .btn:hover {
            background: #0052a3;
        }

        section {
            margin-bottom: 70px;
        }

        h2 {
            font-size: 2em;
            margin-bottom: 30px;
            color: #000;
            font-weight: 700;
            padding-bottom: 15px;
            border-bottom: 2px solid #e0e0e0;
        }

        h3 {
            font-size: 1.4em;
            margin: 35px 0 20px;
            color: #000;
            font-weight: 600;
        }

        p {
            font-size: 1.05em;
            line-height: 1.8;
            color: #333;
            margin-bottom: 20px;
        }

        .tldr {
            background: #f8f9fa;
            padding: 30px;
            border-left: 4px solid #0066cc;
            margin: 30px 0;
            border-radius: 4px;
        }

        .tldr p {
            margin: 0;
            font-size: 1.15em;
        }

        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .feature {
            padding: 0;
        }

        .feature h4 {
            font-size: 1.15em;
            margin-bottom: 12px;
            color: #000;
            font-weight: 600;
        }

        .feature p {
            color: #555;
            line-height: 1.7;
            font-size: 1em;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 30px 0;
            font-size: 0.95em;
        }

        th, td {
            padding: 12px 15px;
            text-align: left;
            border-bottom: 1px solid #e0e0e0;
        }

        th {
            background: #f8f9fa;
            color: #333;
            font-weight: 600;
            border-top: 2px solid #e0e0e0;
        }

        tbody tr:hover {
            background: #f8f9fa;
        }

        .video-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 30px;
            margin: 40px 0;
        }

        .video-item {
            text-align: center;
        }

        .video-item img {
            width: 100%;
            border-radius: 4px;
            margin-bottom: 15px;
            border: 1px solid #e0e0e0;
        }

        .video-caption {
            font-weight: 600;
            color: #333;
            margin-bottom: 5px;
            font-size: 1em;
        }

        .video-time {
            color: #0066cc;
            font-weight: 600;
            font-size: 1.1em;
        }

        code {
            background: #f4f4f4;
            color: #333;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Monaco', 'Menlo', 'Courier New', monospace;
            font-size: 0.9em;
        }

        pre {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            padding: 20px;
            border-radius: 4px;
            overflow-x: auto;
            margin: 25px 0;
        }

        pre code {
            background: none;
            padding: 0;
            color: #333;
        }

        .highlight {
            font-weight: 600;
            color: #000;
        }

        ul {
            margin: 20px 0;
            padding-left: 0;
            list-style: none;
        }

        ul li {
            padding: 8px 0 8px 30px;
            position: relative;
            line-height: 1.7;
        }

        ul li:before {
            content: "✓";
            position: absolute;
            left: 0;
            color: #0066cc;
            font-weight: 600;
        }

        .algo-box {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 4px;
            margin: 30px 0;
        }

        footer {
            text-align: center;
            padding: 50px 20px 30px;
            color: #666;
            font-size: 0.95em;
            border-top: 1px solid #e0e0e0;
            margin-top: 80px;
        }

        footer a {
            color: #0066cc;
            text-decoration: none;
        }

        footer a:hover {
            text-decoration: underline;
        }

        @media (max-width: 768px) {
            h1 {
                font-size: 2em;
            }

            h2 {
                font-size: 1.6em;
            }

            .features {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>LiteAttention: A Temporal Sparse Attention for Diffusion Transformers</h1>
            <div class="authors">
                <a href="https://github.com/dor-shmilovich">Dor Shmilovich</a>, 
                <a href="https://github.com/tonywu71">Tony Wu</a>, 
                <a href="https://github.com/aviadbd">Aviad Dahan</a>,
                <a href="https://github.com/yuval-domb">Yuval Domb</a>
            </div>
            <div class="affiliation">
                <a href="https://moonmath.ai">MoonMath.ai</a>
            </div>
            <div class="links">
                <a href="https://arxiv.org" class="btn">Paper</a>
                <a href="https://github.com/moonmath-ai/LiteAttention" class="btn">Code</a>
                <a href="https://github.com/moonmath-ai/LiteAttention" class="btn">arXiv</a>
                <a href="https://moonmath.ai" class="btn">MoonMath.ai</a>
            </div>
        </header>

        <section>
            <h2>TL;DR</h2>
            <div class="tldr">
                <p>
                    <strong>LiteAttention</strong> is a <strong>training-free</strong> temporal sparse attention mechanism that exploits the slow evolution of attention patterns across diffusion timesteps. 
                    By identifying non-essential tiles early and propagating skip decisions forward, it achieves <span class="highlight">up to 54% attention sparsity</span> on production video diffusion models 
                    <span class="highlight">with no degradation in generation quality</span>.
                </p>
            </div>
        </section>

        <section>
            <h2>Overview</h2>
            <p>
                The LiteAttention framework addresses computational bottlenecks in state-of-the-art video generation models. 
                Without requiring any fine-tuning of pre-trained models, it leverages the <strong>temporal coherence of sparsity patterns</strong> 
                across denoising timesteps to significantly speed up the inference process.
            </p>
            <p>
                Through a co-design of algorithms and systems, LiteAttention provides an end-to-end solution that achieves measurable speedups 
                on real-world hardware, offering greater efficiency and lower costs for video generation tasks.
            </p>
        </section>

        <section>
            <h2>Key Features</h2>
            <div class="features">
                <div class="feature">
                    <h4>Evolutionary Computation Skips</h4>
                    <p>Identify non-essential tiles once during early denoising and propagate skip decisions forward through the entire trajectory.</p>
                </div>
                <div class="feature">
                    <h4>Full-Stage Elimination</h4>
                    <p>Skip the entire attention iteration (QK product, softmax, PV product) for marked tiles, not just partial stages.</p>
                </div>
                <div class="feature">
                    <h4>Error Calibration</h4>
                    <p>Assign different error bounds to different timesteps, with stricter bounds for earlier timesteps that have greater influence.</p>
                </div>
                <div class="feature">
                    <h4>Zero Training Required</h4>
                    <p>Production-ready, requires no model retraining or architectural modifications.</p>
                </div>
            </div>
        </section>

        <section>
            <h2>Efficient Sparse Attention via QK-Skip Algorithm</h2>
            <p>
                LiteAttention introduces <strong>evolutionary computation skips</strong> that leverage temporal coherence in diffusion attention.
            </p>
            <div class="algo-box">
                <h4 style="margin-bottom: 15px; color: #000; font-size: 1.1em;">QK-Skip Algorithm</h4>
                <p style="margin-bottom: 15px;">
                    Unlike dynamic methods that repeatedly recompute sparsity at every step (incurring 10-20% overhead), 
                    LiteAttention maintains a Skip-Mask that is updated at each timestep. As the diffusion process progresses, 
                    the number of tiles marked for skipping gradually increases.
                </p>
                <p style="margin-bottom: 0;">
                    Once a tile is marked as skippable, the entire attention iteration is bypassed for subsequent timesteps, 
                    eliminating redundant computations without repeated profiling.
                </p>
            </div>
            <p><strong>This approach combines:</strong></p>
            <ul>
                <li><strong>Content adaptivity</strong> of dynamic sparsity (patterns derived from actual attention statistics)</li>
                <li><strong>Efficiency</strong> of static sparsity (no per-step re-evaluation overhead)</li>
                <li><strong>Completeness</strong> of full computation elimination</li>
            </ul>
        </section>

        <section>
            <h2>Quantitative Evaluation</h2>
            <p>
                LiteAttention achieves state-of-the-art video quality with significant speedups compared to other sparse attention methods, evaluated using VBench metrics on production video diffusion models.
            </p>
            
            <h3>Wan2.1-14B Detailed Comparison</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>AQ ↑</th>
                        <th>BC ↑</th>
                        <th>DD ↑</th>
                        <th>IQ ↑</th>
                        <th>SC ↑</th>
                        <th>TF ↑</th>
                        <th>TS ↑</th>
                        <th>Sparsity ↑</th>
                        <th>Runtime ↓</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>FlashAttention3</td>
                        <td>0.676</td>
                        <td>0.977</td>
                        <td>0.417</td>
                        <td><strong>68.74</strong></td>
                        <td>0.965</td>
                        <td>0.962</td>
                        <td>0.137</td>
                        <td>0%</td>
                        <td>1707 sec</td>
                    </tr>
                    <tr>
                        <td>SparseVideoGen</td>
                        <td><em>0.665</em></td>
                        <td><em>0.971</em></td>
                        <td><strong>0.500</strong></td>
                        <td><em>68.58</em></td>
                        <td>0.962</td>
                        <td>0.959</td>
                        <td><em>0.066</em></td>
                        <td><em>66%</em></td>
                        <td><em>1019 sec</em></td>
                    </tr>
                    <tr>
                        <td>RadialAttention</td>
                        <td>0.660</td>
                        <td>0.970</td>
                        <td><em>0.417</em></td>
                        <td>64.73</td>
                        <td><strong>0.964</strong></td>
                        <td><strong>0.972</strong></td>
                        <td>0.061</td>
                        <td><strong>74%</strong></td>
                        <td>1192 sec</td>
                    </tr>
                    <tr style="background: #fffef0;">
                        <td><strong>LiteAttention</strong></td>
                        <td><strong>0.677</strong></td>
                        <td><strong>0.975</strong></td>
                        <td><strong>0.500</strong></td>
                        <td><em>66.76</em></td>
                        <td><em>0.963</em></td>
                        <td><em>0.962</em></td>
                        <td><strong>0.142</strong></td>
                        <td>42%</td>
                        <td><strong>902 sec</strong></td>
                    </tr>
                </tbody>
            </table>
            
            <h3>Wan2.2-14B Detailed Comparison</h3>
            <table>
                <thead>
                    <tr>
                        <th>Method</th>
                        <th>AQ ↑</th>
                        <th>BC ↑</th>
                        <th>DD ↑</th>
                        <th>IQ ↑</th>
                        <th>SC ↑</th>
                        <th>TF ↑</th>
                        <th>TS ↑</th>
                        <th>Sparsity ↑</th>
                        <th>Runtime ↓</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>FlashAttention3</td>
                        <td>0.693</td>
                        <td>0.977</td>
                        <td><strong>0.583</strong></td>
                        <td><strong>72.73</strong></td>
                        <td>0.970</td>
                        <td>0.953</td>
                        <td>0.133</td>
                        <td>0%</td>
                        <td>1473 sec</td>
                    </tr>
                    <tr>
                        <td>SparseVideoGen</td>
                        <td><em>0.689</em></td>
                        <td>0.962</td>
                        <td><em>0.417</em></td>
                        <td><em>72.24</em></td>
                        <td>0.961</td>
                        <td><em>0.952</em></td>
                        <td><em>0.061</em></td>
                        <td><strong>66%</strong></td>
                        <td><em>1022 sec</em></td>
                    </tr>
                    <tr>
                        <td>RadialAttention</td>
                        <td>0.682</td>
                        <td><em>0.974</em></td>
                        <td><strong>0.500</strong></td>
                        <td><strong>72.73</strong></td>
                        <td><em>0.967</em></td>
                        <td>0.947</td>
                        <td><em>0.061</em></td>
                        <td><strong>66%</strong></td>
                        <td>1207 sec</td>
                    </tr>
                    <tr style="background: #fffef0;">
                        <td><strong>LiteAttention</strong></td>
                        <td><strong>0.698</strong></td>
                        <td><strong>0.977</strong></td>
                        <td><strong>0.500</strong></td>
                        <td>71.44</td>
                        <td><strong>0.969</strong></td>
                        <td><strong>0.953</strong></td>
                        <td><strong>0.135</strong></td>
                        <td><em>32%</em></td>
                        <td><strong>893 sec</strong></td>
                    </tr>
                </tbody>
            </table>
            <p style="font-size: 0.95em; color: #666; margin-top: 15px;">
                <em>Best results in <strong>bold</strong>, second-best in <em>italic</em></em><br>
                <em>VBench Metrics: AQ (Aesthetic Quality), BC (Background Consistency), DD (Dynamic Degree), 
                IQ (Imaging Quality), SC (Subject Consistency), TF (Temporal Flickering), TS (Temporal Style)</em>
            </p>
            
            <h3>Speedup Analysis</h3>
            <p style="margin-top: 30px;">
                LiteAttention achieves significant speedups over FlashAttention3 baseline:
            </p>
            <ul style="margin: 20px 0; padding-left: 30px; list-style: disc;">
                <li style="margin: 10px 0;"><strong>Wan2.1-14B</strong>: 1707 sec → 902 sec = <strong>1.89× speedup</strong> (47% time reduction)</li>
                <li style="margin: 10px 0;"><strong>Wan2.2-14B</strong>: 1473 sec → 893 sec = <strong>1.65× speedup</strong> (39% time reduction)</li>
            </ul>
            <p>
                LiteAttention achieves the <strong>best runtime</strong> on both models while maintaining <strong>superior quality metrics</strong> 
                compared to SparseVideoGen and RadialAttention.
            </p>
            
            <h3>Ablation Study: Sparsity vs Runtime</h3>
            <p style="margin-top: 30px;">
                Our ablation studies demonstrate that runtime improvement scales with attention sparsity:
            </p>
            <table>
                <thead>
                    <tr>
                        <th>Sparsity</th>
                        <th>Self-Attention Runtime</th>
                        <th>Runtime Improvement</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>0%</td>
                        <td>695 sec</td>
                        <td>0% (baseline)</td>
                    </tr>
                    <tr>
                        <td>21%</td>
                        <td>573 sec</td>
                        <td>18%</td>
                    </tr>
                    <tr>
                        <td>42%</td>
                        <td>418 sec</td>
                        <td>40%</td>
                    </tr>
                    <tr>
                        <td>57%</td>
                        <td>308 sec</td>
                        <td>56%</td>
                    </tr>
                    <tr>
                        <td>77%</td>
                        <td>163 sec</td>
                        <td>77%</td>
                    </tr>
                </tbody>
            </table>
            <p style="margin-top: 20px;">
                The near-linear scaling between sparsity and runtime improvement demonstrates the efficiency of our QK-Skip algorithm.
            </p>
        </section>

        <section>
            <h2>Gallery - Wan2.1-14B Generation Times</h2>
            <p>
                LiteAttention provides significant speedups on video generation tasks. Below are generation times and visual comparisons at different threshold settings:
            </p>
            <div class="video-grid">
                <div class="video-item">
                    <img src="../assets/wan_outputs/baseline.gif" alt="Baseline">
                    <div class="video-caption">Baseline (no skip)</div>
                    <div class="video-time">23m 51s</div>
                </div>
                <div class="video-item">
                    <img src="../assets/wan_outputs/minus10.gif" alt="Threshold -10">
                    <div class="video-caption">Threshold -10</div>
                    <div class="video-time">14m 19s</div>
                </div>
                <div class="video-item">
                    <img src="../assets/wan_outputs/minus3.gif" alt="Threshold -3">
                    <div class="video-caption">Threshold -3</div>
                    <div class="video-time">11m 46s</div>
                </div>
                <div class="video-item">
                    <img src="../assets/wan_outputs/zero.gif" alt="Threshold 0">
                    <div class="video-caption">Threshold 0</div>
                    <div class="video-time">8m 31s</div>
                </div>
            </div>
        </section>

        <section>
            <h2>Quick Start</h2>
            <h3>Installation</h3>
            <pre><code>git clone https://github.com/moonmath-ai/LiteAttention.git
cd LiteAttention/hopper
python setup.py install</code></pre>

            <h3>Basic Usage</h3>
            <pre><code>from lite_attention import LiteAttention

# Initialize with threshold
attn = LiteAttention(threshold=-6.0)

# Use in your model
output = attn(query, key, value, scale)</code></pre>

            <p style="margin-top: 25px;">
                See the <a href="https://github.com/moonmath-ai/LiteAttention" style="color: #0066cc; font-weight: 600;">GitHub repository</a> 
                for detailed documentation and examples.
            </p>
        </section>

        <section>
            <h2>BibTeX</h2>
            <pre><code>@inproceedings{shmilovich2025liteattention,
  title={LiteAttention: A Temporal Sparse Attention for Diffusion Transformers},
  author={Shmilovich, Dor and Wu, Tony and Dahan, Aviad and Domb, Yuval},
  booktitle={NeurIPS},
  year={2025}
}</code></pre>
        </section>

        <section>
            <h2>Acknowledgements</h2>
            <p>
                LiteAttention is built on top of <a href="https://github.com/Dao-AILab/flash-attention" style="color: #0066cc;">FlashAttention3</a> 
                by Tri Dao and contributors. We thank the FlashAttention team for their foundational work on efficient attention mechanisms.
            </p>
            <p>
                We also thank the teams behind 
                <a href="https://github.com/svg-project/Sparse-VideoGen" style="color: #0066cc;">SparseVideoGen</a>, 
                <a href="https://github.com/mit-han-lab/radial-attention" style="color: #0066cc;">RadialAttention</a>, 
                <a href="https://github.com/thu-ml/SageAttention" style="color: #0066cc;">SageAttention</a>, 
                <a href="https://github.com/Wan-Video/Wan2.1" style="color: #0066cc;">Wan2.1</a>, and 
                <a href="https://github.com/Lightricks/LTX-Video" style="color: #0066cc;">LTX-Video</a> 
                for their insights and benchmarking support.
            </p>
        </section>
    </div>

    <footer>
        <p>&copy; 2025 MoonMath.ai. Released under BSD-3-Clause and MIT licenses.</p>
        <p style="margin-top: 10px;">
            <a href="https://github.com/moonmath-ai/LiteAttention">GitHub</a> | 
            <a href="https://moonmath.ai">MoonMath.ai</a>
        </p>
    </footer>
</body>
</html>
